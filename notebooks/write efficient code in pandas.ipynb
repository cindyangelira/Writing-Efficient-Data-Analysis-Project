{"cells":[{"source":"# WRITING EFFICIENT CODE IN PANDAS\n","metadata":{},"id":"7607bdb2-1707-4361-a984-1c443fe84370","cell_type":"markdown"},{"source":"# Import any packages you want to use here\nimport time\nimport numpy as np\nimport pandas as pd","metadata":{"executionTime":28,"lastSuccessfullyExecutedCode":"# Import any packages you want to use here\nimport time\nimport numpy as np\nimport pandas as pd"},"id":"7f26dd6a-20aa-4d19-8d3f-b8f64fba1821","cell_type":"code","execution_count":3,"outputs":[]},{"source":"## Take Notes\n\nAdd notes here about the concepts you've learned and code cells with code you want to keep.","metadata":{},"id":"a0ac303b-ad44-4690-a9f0-a70619fcabc4","cell_type":"markdown"},{"source":"# Dataset","metadata":{},"id":"540470d7-eb27-442b-b0d5-ab28b0a7da96","cell_type":"markdown"},{"source":"# Add your code snippets here\npoker_hand = pd.read_csv(\"poker_hand.csv\")\nnames = pd.read_csv(\"Popular_Baby_Names.csv\")\nrestaurant_data = pd.read_csv(\"restaurant_data.csv\")","metadata":{"executionTime":64,"lastSuccessfullyExecutedCode":"# Add your code snippets here\npoker_hand = pd.read_csv(\"poker_hand.csv\")\nnames = pd.read_csv(\"Popular_Baby_Names.csv\")\nrestaurant_data = pd.read_csv(\"restaurant_data.csv\")"},"id":"7869e914-9bb1-4f2d-a48b-5ab87e36e9b7","cell_type":"code","execution_count":31,"outputs":[]},{"source":"poker_hand.head()","metadata":{"executionTime":70,"lastSuccessfullyExecutedCode":"poker_hand.head()","visualizeDataframe":false,"chartConfig":{"bar":{"hasRoundedCorners":true,"stacked":false},"type":"bar","version":"v1"}},"cell_type":"code","id":"b57901c8-34a7-4d45-93dd-538c55abe88a","execution_count":5,"outputs":[{"output_type":"execute_result","execution_count":5,"data":{"application/com.datacamp.data-table.v1+json":{"table":{"schema":{"fields":[{"name":"index","type":"integer"},{"name":"S1","type":"integer"},{"name":"R1","type":"integer"},{"name":"S2","type":"integer"},{"name":"R2","type":"integer"},{"name":"S3","type":"integer"},{"name":"R3","type":"integer"},{"name":"S4","type":"integer"},{"name":"R4","type":"integer"},{"name":"S5","type":"integer"},{"name":"R5","type":"integer"},{"name":"Class","type":"integer"}],"primaryKey":["index"],"pandas_version":"1.4.0"},"data":[{"index":0,"S1":1,"R1":10,"S2":1,"R2":11,"S3":1,"R3":13,"S4":1,"R4":12,"S5":1,"R5":1,"Class":9},{"index":1,"S1":2,"R1":11,"S2":2,"R2":13,"S3":2,"R3":10,"S4":2,"R4":12,"S5":2,"R5":1,"Class":9},{"index":2,"S1":3,"R1":12,"S2":3,"R2":11,"S3":3,"R3":13,"S4":3,"R4":10,"S5":3,"R5":1,"Class":9},{"index":3,"S1":4,"R1":10,"S2":4,"R2":11,"S3":4,"R3":1,"S4":4,"R4":13,"S5":4,"R5":12,"Class":9},{"index":4,"S1":4,"R1":1,"S2":4,"R2":13,"S3":4,"R3":12,"S4":4,"R4":11,"S5":4,"R5":10,"Class":9}]},"total_rows":5,"truncation_type":null},"text/plain":"   S1  R1  S2  R2  S3  R3  S4  R4  S5  R5  Class\n0   1  10   1  11   1  13   1  12   1   1      9\n1   2  11   2  13   2  10   2  12   2   1      9\n2   3  12   3  11   3  13   3  10   3   1      9\n3   4  10   4  11   4   1   4  13   4  12      9\n4   4   1   4  13   4  12   4  11   4  10      9","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>S1</th>\n      <th>R1</th>\n      <th>S2</th>\n      <th>R2</th>\n      <th>S3</th>\n      <th>R3</th>\n      <th>S4</th>\n      <th>R4</th>\n      <th>S5</th>\n      <th>R5</th>\n      <th>Class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>10</td>\n      <td>1</td>\n      <td>11</td>\n      <td>1</td>\n      <td>13</td>\n      <td>1</td>\n      <td>12</td>\n      <td>1</td>\n      <td>1</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>11</td>\n      <td>2</td>\n      <td>13</td>\n      <td>2</td>\n      <td>10</td>\n      <td>2</td>\n      <td>12</td>\n      <td>2</td>\n      <td>1</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>12</td>\n      <td>3</td>\n      <td>11</td>\n      <td>3</td>\n      <td>13</td>\n      <td>3</td>\n      <td>10</td>\n      <td>3</td>\n      <td>1</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>10</td>\n      <td>4</td>\n      <td>11</td>\n      <td>4</td>\n      <td>1</td>\n      <td>4</td>\n      <td>13</td>\n      <td>4</td>\n      <td>12</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>1</td>\n      <td>4</td>\n      <td>13</td>\n      <td>4</td>\n      <td>12</td>\n      <td>4</td>\n      <td>11</td>\n      <td>4</td>\n      <td>10</td>\n      <td>9</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"source":"names.head()","metadata":{"executionTime":74,"lastSuccessfullyExecutedCode":"names.head()"},"cell_type":"code","id":"cc54c0ee-aa04-4870-abe4-a330a7612fac","execution_count":18,"outputs":[{"output_type":"execute_result","execution_count":18,"data":{"application/com.datacamp.data-table.v1+json":{"table":{"schema":{"fields":[{"name":"index","type":"integer"},{"name":"Year of Birth","type":"integer"},{"name":"Gender","type":"string"},{"name":"Ethnicity","type":"string"},{"name":"Child's First Name","type":"string"},{"name":"Count","type":"integer"},{"name":"Rank","type":"integer"}],"primaryKey":["index"],"pandas_version":"1.4.0"},"data":[{"index":0,"Year of Birth":2011,"Gender":"FEMALE","Ethnicity":"ASIAN AND PACIFIC ISLANDER","Child's First Name":"SOPHIA","Count":119,"Rank":1},{"index":1,"Year of Birth":2011,"Gender":"FEMALE","Ethnicity":"ASIAN AND PACIFIC ISLANDER","Child's First Name":"CHLOE","Count":106,"Rank":2},{"index":2,"Year of Birth":2011,"Gender":"FEMALE","Ethnicity":"ASIAN AND PACIFIC ISLANDER","Child's First Name":"EMILY","Count":93,"Rank":3},{"index":3,"Year of Birth":2011,"Gender":"FEMALE","Ethnicity":"ASIAN AND PACIFIC ISLANDER","Child's First Name":"OLIVIA","Count":89,"Rank":4},{"index":4,"Year of Birth":2011,"Gender":"FEMALE","Ethnicity":"ASIAN AND PACIFIC ISLANDER","Child's First Name":"EMMA","Count":75,"Rank":5}]},"total_rows":5,"truncation_type":null},"text/plain":"   Year of Birth  Gender  ... Count Rank\n0           2011  FEMALE  ...   119    1\n1           2011  FEMALE  ...   106    2\n2           2011  FEMALE  ...    93    3\n3           2011  FEMALE  ...    89    4\n4           2011  FEMALE  ...    75    5\n\n[5 rows x 6 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Year of Birth</th>\n      <th>Gender</th>\n      <th>Ethnicity</th>\n      <th>Child's First Name</th>\n      <th>Count</th>\n      <th>Rank</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2011</td>\n      <td>FEMALE</td>\n      <td>ASIAN AND PACIFIC ISLANDER</td>\n      <td>SOPHIA</td>\n      <td>119</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2011</td>\n      <td>FEMALE</td>\n      <td>ASIAN AND PACIFIC ISLANDER</td>\n      <td>CHLOE</td>\n      <td>106</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2011</td>\n      <td>FEMALE</td>\n      <td>ASIAN AND PACIFIC ISLANDER</td>\n      <td>EMILY</td>\n      <td>93</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2011</td>\n      <td>FEMALE</td>\n      <td>ASIAN AND PACIFIC ISLANDER</td>\n      <td>OLIVIA</td>\n      <td>89</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2011</td>\n      <td>FEMALE</td>\n      <td>ASIAN AND PACIFIC ISLANDER</td>\n      <td>EMMA</td>\n      <td>75</td>\n      <td>5</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"source":"restaurant_data.head()","metadata":{"executionTime":88,"lastSuccessfullyExecutedCode":"restaurant_data.head()"},"cell_type":"code","id":"4a31140a-2ae9-439c-a084-33f0d5a91f41","execution_count":32,"outputs":[{"output_type":"execute_result","execution_count":32,"data":{"application/com.datacamp.data-table.v1+json":{"table":{"schema":{"fields":[{"name":"index","type":"integer"},{"name":"total_bill","type":"number"},{"name":"tip","type":"number"},{"name":"sex","type":"string"},{"name":"smoker","type":"string"},{"name":"day","type":"string"},{"name":"time","type":"string"},{"name":"size","type":"integer"}],"primaryKey":["index"],"pandas_version":"1.4.0"},"data":[{"index":0,"total_bill":16.99,"tip":1.01,"sex":"Female","smoker":"No","day":"Sun","time":"Dinner","size":2},{"index":1,"total_bill":10.34,"tip":1.66,"sex":"Male","smoker":"No","day":"Sun","time":"Dinner","size":3},{"index":2,"total_bill":21.01,"tip":3.5,"sex":"Male","smoker":"No","day":"Sun","time":"Dinner","size":3},{"index":3,"total_bill":23.68,"tip":3.31,"sex":"Male","smoker":"No","day":"Sun","time":"Dinner","size":2},{"index":4,"total_bill":24.59,"tip":3.61,"sex":"Female","smoker":"No","day":"Sun","time":"Dinner","size":4}]},"total_rows":5,"truncation_type":null},"text/plain":"   total_bill   tip     sex smoker  day    time  size\n0       16.99  1.01  Female     No  Sun  Dinner     2\n1       10.34  1.66    Male     No  Sun  Dinner     3\n2       21.01  3.50    Male     No  Sun  Dinner     3\n3       23.68  3.31    Male     No  Sun  Dinner     2\n4       24.59  3.61  Female     No  Sun  Dinner     4","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>total_bill</th>\n      <th>tip</th>\n      <th>sex</th>\n      <th>smoker</th>\n      <th>day</th>\n      <th>time</th>\n      <th>size</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>16.99</td>\n      <td>1.01</td>\n      <td>Female</td>\n      <td>No</td>\n      <td>Sun</td>\n      <td>Dinner</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>10.34</td>\n      <td>1.66</td>\n      <td>Male</td>\n      <td>No</td>\n      <td>Sun</td>\n      <td>Dinner</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>21.01</td>\n      <td>3.50</td>\n      <td>Male</td>\n      <td>No</td>\n      <td>Sun</td>\n      <td>Dinner</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>23.68</td>\n      <td>3.31</td>\n      <td>Male</td>\n      <td>No</td>\n      <td>Sun</td>\n      <td>Dinner</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>24.59</td>\n      <td>3.61</td>\n      <td>Female</td>\n      <td>No</td>\n      <td>Sun</td>\n      <td>Dinner</td>\n      <td>4</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"source":"# 1. SELECTING ROW AND COLUMN","metadata":{},"cell_type":"markdown","id":"092f28e6-22a3-4280-9cf6-a6293dc2136a"},{"source":"### Note\n1. .loc better for column\n2. .iloc better for rows\n\nRow selection: `loc` vs `iloc`\nA big part of working with DataFrames is to locate specific entries in the dataset. You can locate rows in two ways:\n\nBy a specific value of a column (feature).\nBy the index of the rows (index). In this exercise, we will focus on the second way.\nIf you have previous experience with pandas, you should be familiar with the .loc and .iloc indexers, which stands for 'location' and 'index location' respectively. In most cases, the indices will be the same as the position of each row in the Dataframe (e.g. the row with index 13 will be the 14th entry).\n\nWhile we can use both functions to perform the same task, we are interested in which is the most efficient in terms of speed.","metadata":{},"cell_type":"markdown","id":"da32e11f-0149-41b6-ab42-c68031afa0d6"},{"source":"# Define the range of rows to select: row_nums\nrow_nums = range(0, 1000)\n\n# Select the rows using .loc[] and row_nums and record the time before and after\nloc_start_time = time.time()\nrows = poker_hand.loc[row_nums]\nloc_end_time = time.time()\n\n# Print the time it took to select the rows using .loc\nprint(\"Time using .loc[]: {} sec\".format(loc_end_time - loc_start_time))\n\n# Select the rows using .iloc[] and row_nums and record the time before and after\niloc_start_time = time.time()\nrows = poker_hand.iloc[row_nums]\niloc_end_time = time.time()\n\n# Print the time it took to select the rows using .iloc\nprint(\"Time using .iloc[]: {} sec\".format(iloc_end_time - iloc_start_time))","metadata":{"executionTime":56,"lastSuccessfullyExecutedCode":"# Define the range of rows to select: row_nums\nrow_nums = range(0, 1000)\n\n# Select the rows using .loc[] and row_nums and record the time before and after\nloc_start_time = time.time()\nrows = poker_hand.loc[row_nums]\nloc_end_time = time.time()\n\n# Print the time it took to select the rows using .loc\nprint(\"Time using .loc[]: {} sec\".format(loc_end_time - loc_start_time))\n\n# Select the rows using .iloc[] and row_nums and record the time before and after\niloc_start_time = time.time()\nrows = poker_hand.iloc[row_nums]\niloc_end_time = time.time()\n\n# Print the time it took to select the rows using .iloc\nprint(\"Time using .iloc[]: {} sec\".format(iloc_end_time - iloc_start_time))"},"cell_type":"code","id":"29a5914b-99cb-4614-b8d7-cb68238b4344","execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":"Time using .loc[]: 0.0017616748809814453 sec\nTime using .iloc[]: 0.0005860328674316406 sec\n"}]},{"source":"### Column selection: `.iloc[]` vs by name\nIn the previous exercise, you saw how the `.loc[]` and `.iloc[]` functions can be used to locate specific rows of a DataFrame (based on the index). Turns out, the `.iloc[]` function performs a lot faster (~ 2 times) for this task!\n\nAnother important task is to find the faster function to select the targeted features (columns) of a DataFrame. In this exercise, we will compare the following:\n\nusing the index locator .iloc()\nusing the names of the columns While we can use both functions to perform the same task, we are interested in which is the most efficient in terms of speed.\nIn this exercise, you will continue working with the poker data which is stored in poker_hands. Take a second to examine the structure of this DataFrame by calling poker_hands.head() in the console!","metadata":{},"cell_type":"markdown","id":"ecef8fe7-e8b8-4aa2-b53c-ba9ee5ecbc85"},{"source":"# Use .iloc to select the first, fourth, fifth, seventh and eighth column and record the times before and after\niloc_start_time = time.time()\ncols = poker_hand.iloc[:,[0,3,4,6,7]]\niloc_end_time = time.time()\n\n# Print the time it took\nprint(\"Time using .iloc[] : {} sec\".format(iloc_end_time - iloc_start_time))\n\n# Use simple column selection to select the first, fourth, fifth, seventh and eighth column and record the times before and after\nnames_start_time = time.time()\ncols = poker_hand[['S1', 'S2', 'R2', 'R3', 'S4']]\nnames_end_time = time.time()\n\n# Print the time it took\nprint(\"Time using selection by name : {} sec\".format(names_end_time - names_start_time))","metadata":{"executionTime":39,"lastSuccessfullyExecutedCode":"# Use .iloc to select the first, fourth, fifth, seventh and eighth column and record the times before and after\niloc_start_time = time.time()\ncols = poker_hand.iloc[:,[0,3,4,6,7]]\niloc_end_time = time.time()\n\n# Print the time it took\nprint(\"Time using .iloc[] : {} sec\".format(iloc_end_time - iloc_start_time))\n\n# Use simple column selection to select the first, fourth, fifth, seventh and eighth column and record the times before and after\nnames_start_time = time.time()\ncols = poker_hand[['S1', 'S2', 'R2', 'R3', 'S4']]\nnames_end_time = time.time()\n\n# Print the time it took\nprint(\"Time using selection by name : {} sec\".format(names_end_time - names_start_time))"},"cell_type":"code","id":"9da96b96-b025-48d3-8292-9d8626b42171","execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":"Time using .iloc[] : 0.0008645057678222656 sec\nTime using selection by name : 0.0012655258178710938 sec\n"}]},{"source":"### Random row selection\nIn this exercise, you will compare the two methods described for selecting random rows (entries) with replacement in a pandas DataFrame:\n\nThe built-in pandas function `.random()`\nThe NumPy random integer number generator `np.random.randint()`\nGenerally, in the fields of statistics and machine learning, when we need to train an algorithm, we train the algorithm on the 75% of the available data and then test the performance on the remaining 25% of the data.\n\nFor this exercise, we will randomly sample the 75% percent of all the played poker hands available, using each of the above methods, and check which method is more efficient in terms of speed.\n\n**Built-in function run faster**","metadata":{},"cell_type":"markdown","id":"72a0b508-6a53-4302-8a0f-3389715298f3"},{"source":"# Extract number of rows in dataset\nN=poker_hand.shape[0]\n\n# Select and time the selection of the 75% of the dataset's rows\nrand_start_time = time.time()\npoker_hand.iloc[np.random.randint(low=0, high=N, size=int(0.75 * N))]\nprint(\"Time using Numpy: {} sec\".format(time.time() - rand_start_time))\n\n# Select and time the selection of the 75% of the dataset's rows using sample()\nsamp_start_time = time.time()\npoker_hand.sample(int(0.75 * N), axis=0, replace = True)\nprint(\"Time using .sample: {} sec\".format(time.time() - samp_start_time))","metadata":{"executionTime":39,"lastSuccessfullyExecutedCode":"# Extract number of rows in dataset\nN=poker_hand.shape[0]\n\n# Select and time the selection of the 75% of the dataset's rows\nrand_start_time = time.time()\npoker_hand.iloc[np.random.randint(low=0, high=N, size=int(0.75 * N))]\nprint(\"Time using Numpy: {} sec\".format(time.time() - rand_start_time))\n\n# Select and time the selection of the 75% of the dataset's rows using sample()\nsamp_start_time = time.time()\npoker_hand.sample(int(0.75 * N), axis=0, replace = True)\nprint(\"Time using .sample: {} sec\".format(time.time() - samp_start_time))"},"cell_type":"code","id":"f2977a19-a83d-4828-b865-fa92d6795a6a","execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":"Time using Numpy: 0.002725839614868164 sec\nTime using .sample: 0.0014526844024658203 sec\n"}]},{"source":"### Random column selection\nIn the previous exercise, we examined two ways to select random rows from a pandas DataFrame. We can use the same functions to randomly select columns in a pandas DataFrame.\n\nTo randomly select 4 columns out of the poker dataset, you will use the following two functions:\n\nThe built-in pandas function `.sample()`\nThe NumPy random integer number generator `np.random.randint()`","metadata":{},"cell_type":"markdown","id":"2b48ab1b-859b-4dfd-9cf7-93eeab7aa358"},{"source":"# Extract number of columns in dataset\nD=poker_hand.shape[1]\n\n# Select and time the selection of 4 of the dataset's columns using NumPy\nnp_start_time = time.time()\npoker_hand.iloc[:,np.random.randint(low=0, high=D, size=4)]\nprint(\"Time using NymPy's random.randint(): {} sec\".format(time.time() - np_start_time))\n\n# Select and time the selection of 4 of the dataset's columns using pandas\npd_start_time = time.time()\npoker_hand.sample(4, axis=1)\nprint(\"Time using panda's .sample(): {} sec\".format(time.time() - pd_start_time))","metadata":{"executionTime":41,"lastSuccessfullyExecutedCode":"# Extract number of columns in dataset\nD=poker_hand.shape[1]\n\n# Select and time the selection of 4 of the dataset's columns using NumPy\nnp_start_time = time.time()\npoker_hand.iloc[:,np.random.randint(low=0, high=D, size=4)]\nprint(\"Time using NymPy's random.randint(): {} sec\".format(time.time() - np_start_time))\n\n# Select and time the selection of 4 of the dataset's columns using pandas\npd_start_time = time.time()\npoker_hand.sample(4, axis=1)\nprint(\"Time using panda's .sample(): {} sec\".format(time.time() - pd_start_time))"},"cell_type":"code","id":"d71c1f64-cdc7-4436-8e54-a0f8c9f7eb04","execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":"Time using NymPy's random.randint(): 0.0008451938629150391 sec\nTime using panda's .sample(): 0.0005755424499511719 sec\n"}]},{"source":"# 2. REPLACING VALUE","metadata":{},"cell_type":"markdown","id":"c589ba85-df23-4345-b8b4-55b99d9ec08c"},{"source":"### Replacing scalar values I\nIn this exercise, we will replace a list of values in our dataset by using the `.replace() `method with another list of desired values.\n\nWe will apply the functions in the poker_hands DataFrame. Remember that in the poker_hands DataFrame, each row of columns R1 to R5 represents the rank of each card from a player's poker hand spanning from 1 (Ace) to 13 (King). The Class feature classifies each hand as a category, and the Explanation feature briefly explains each hand.\n\nThe poker_hands DataFrame is already loaded for you, and you can explore the features Class and Explanation.\n\nRemember you can always explore the dataset and see how it changes in the IPython Shell, and refer to the slides in the Slides tab.","metadata":{},"cell_type":"markdown","id":"4e48c8da-d4ad-490b-9cef-403f05b303bb"},{"source":"# Replace Class 1 to -2 \npoker_hands = poker_hand.copy()\npoker_hands['Class'].replace(1, -2, inplace=True)\n# Replace Class 2 to -3\npoker_hands['Class'].replace(2, -3, inplace=True)\n\nprint(poker_hands[['Class', 'S1']])","metadata":{"executionTime":47,"lastSuccessfullyExecutedCode":"# Replace Class 1 to -2 \npoker_hands = poker_hand.copy()\npoker_hands['Class'].replace(1, -2, inplace=True)\n# Replace Class 2 to -3\npoker_hands['Class'].replace(2, -3, inplace=True)\n\nprint(poker_hands[['Class', 'S1']])"},"cell_type":"code","id":"e2584cc1-52ce-41b1-b84f-87c5b4e1bfeb","execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":"       Class  S1\n0          9   1\n1          9   2\n2          9   3\n3          9   4\n4          9   4\n...      ...  ..\n25005      0   3\n25006     -2   4\n25007     -2   2\n25008     -2   2\n25009     -2   1\n\n[25010 rows x 2 columns]\n"}]},{"source":"### Replace scalar values II\nAs discussed in the video, in a pandas DataFrame, it is possible to replace values in a very intuitive way: we locate the position (row and column) in the Dataframe and assign in the new value you want to replace with. In a more pandas-ian way, the .replace() function is available that performs the same task.\n\nYou will be using the names DataFrame which includes, among others, the most popular names in the US by year, gender and ethnicity.\n\nYour task is to replace all the babies that are classified as FEMALE to GIRL using the following methods:\n\nintuitive scalar replacement\nusing the .replace() function","metadata":{},"cell_type":"markdown","id":"6b8b7668-565d-45b9-b93b-b357eb518177"},{"source":"### Replace multiple values I\nIn this exercise, you will apply the .replace() function for the task of replacing multiple values with one or more values. You will again use the names dataset which contains, among others, the most popular names in the US by year, gender and Ethnicity.\n\nThus you want to replace all ethnicities classified as black or white non-hispanics to non-hispanic. Remember, the ethnicities are stated in the dataset as follows:\\\n`['BLACK NON HISP', 'BLACK NON HISPANIC', 'WHITE NON HISP' , 'WHITE NON HISPANIC']` \\\nand should be replaced to 'NON HISPANIC'","metadata":{},"cell_type":"markdown","id":"6be92ba8-bda9-4c7f-8b33-7773161c5b0b"},{"source":"names1 = names.copy()\nstart_time = time.time()\n\n# Replace all non-Hispanic ethnicities with 'NON HISPANIC'\nnames1['Ethnicity'].replace(['BLACK NON HISP', 'BLACK NON HISPANIC', 'WHITE NON HISP' , 'WHITE NON HISPANIC'], 'NON HISPANIC', inplace=True)\n\nprint(\"Time using .replace(): {} sec\".format(time.time() - start_time))","metadata":{"executionTime":42,"lastSuccessfullyExecutedCode":"names1 = names.copy()\nstart_time = time.time()\n\n# Replace all non-Hispanic ethnicities with 'NON HISPANIC'\nnames1['Ethnicity'].replace(['BLACK NON HISP', 'BLACK NON HISPANIC', 'WHITE NON HISP' , 'WHITE NON HISPANIC'], 'NON HISPANIC', inplace=True)\n\nprint(\"Time using .replace(): {} sec\".format(time.time() - start_time))"},"cell_type":"code","id":"e042a16e-108f-42dc-9204-49632c428a89","execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":"Time using .replace(): 0.0028188228607177734 sec\n"}]},{"source":"### Replace multiple values II\nAs discussed in the video, instead of using the .replace() function multiple times to replace multiple values, you can use lists to map the elements you want to replace one to one with those you want to replace them with.\n\nAs you have seen in our popular names dataset, there are two names for the same ethnicity. We want to standardize the naming of each ethnicity by replacing\n\n'ASIAN AND PACI' to 'ASIAN AND PACIFIC ISLANDER'\\\n'BLACK NON HISP' to 'BLACK NON HISPANIC'\\\n'WHITE NON HISP' to 'WHITE NON HISPANIC'\\\nIn the DataFrame names, you are going to replace all the values on the left by the values on the right.","metadata":{},"cell_type":"markdown","id":"baebb768-9d8c-4743-bb7c-b4a62247fd76"},{"source":"names2 = names.copy()\nstart_time = time.time()\n\n# Replace ethnicities as instructed\nnames2['Ethnicity'].replace(['ASIAN AND PACI','BLACK NON HISP', 'WHITE NON HISP'], ['ASIAN AND PACIFIC ISLANDER','BLACK NON HISPANIC','WHITE NON HISPANIC'], inplace=True)\n\nprint(\"Time using .replace(): {} sec\".format(time.time() - start_time))","metadata":{"executionTime":53,"lastSuccessfullyExecutedCode":"names2 = names.copy()\nstart_time = time.time()\n\n# Replace ethnicities as instructed\nnames2['Ethnicity'].replace(['ASIAN AND PACI','BLACK NON HISP', 'WHITE NON HISP'], ['ASIAN AND PACIFIC ISLANDER','BLACK NON HISPANIC','WHITE NON HISPANIC'], inplace=True)\n\nprint(\"Time using .replace(): {} sec\".format(time.time() - start_time))"},"cell_type":"code","id":"826e6d9b-fb0f-4048-8e69-47eb7ddf08e8","execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":"Time using .replace(): 0.0024690628051757812 sec\n"}]},{"source":"### Replace single values I\nIn this exercise, we will apply the following replacing technique of replacing multiple values using dictionaries on a different dataset.\n\nWe will apply the functions in the data DataFrame. Each row represents the rank of 5 cards from a playing card deck, spanning from 1 (Ace) to 13 (King) (features R1, R2, R3, R4, R5). The feature 'Class' classifies each row to a category (from 0 to 9) and the feature 'Explanation' gives a brief explanation of what each class represents.\n\nThe purpose of this exercise is to categorize the two types of flush in the game ('Royal flush' and 'Straight flush') under the 'Flush' name.\n\n**Replace Royal flush or Straight flush to Flush**\\\n`poker_hands.replace({'Explanation' :{'Royal flush':'Flush', 'Straight flush':'Flush'}}, inplace=True)\nprint(poker_hands['Explanation'].head())`","metadata":{},"cell_type":"markdown","id":"461e4edd-b6f6-4906-83f7-e1f4711d449b"},{"source":"### Replace single values II\nFor this exercise, we will be using the names DataFrame. In this dataset, the column 'Rank' shows the ranking of each name by year. For this exercise, you will use dictionaries to replace the first ranked name of every year as 'FIRST', the second name as 'SECOND' and the third name as 'THIRD'.\n\nYou will use dictionaries to replace one single value per key.\n\nYou can already see the first 5 names of the data, which correspond to the 5 most popular names for all the females belonging to the 'ASIAN AND PACIFIC ISLANDER' ethnicity in 2011.","metadata":{},"cell_type":"markdown","id":"503f191c-7ec4-428a-94cf-4588666982ba"},{"source":"names3 = names.copy()\n\n# Replace the number rank by a string\nnames3['Rank'].replace({1: 'FIRST', 2:'SECOND', 3:'THIRD'}, inplace=True)\nprint(names3.head())","metadata":{"executionTime":51,"lastSuccessfullyExecutedCode":"names3 = names.copy()\n\n# Replace the number rank by a string\nnames3['Rank'].replace({1: 'FIRST', 2:'SECOND', 3:'THIRD'}, inplace=True)\nprint(names3.head())"},"cell_type":"code","id":"c2fd3e55-6bd1-40aa-a87a-9ab97d481675","execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":"   Year of Birth  Gender  ... Count    Rank\n0           2011  FEMALE  ...   119   FIRST\n1           2011  FEMALE  ...   106  SECOND\n2           2011  FEMALE  ...    93   THIRD\n3           2011  FEMALE  ...    89       4\n4           2011  FEMALE  ...    75       5\n\n[5 rows x 6 columns]\n"}]},{"source":"### Replace multiple values III\nAs you saw in the video, you can use dictionaries to replace multiple values with just one value, even from multiple columns. To show the usefulness of replacing with dictionaries, you will use the names dataset one more time.\n\nIn this dataset, the column 'Rank' shows which rank each name reached every year. You will change the rank of the first three ranked names of every year to 'MEDAL' and those from 4th and 5th place to 'ALMOST MEDAL'.\n\nYou can already see the first 5 names of the data, which correspond to the 5 most popular names for all the females belonging to the 'ASIAN AND PACIFIC ISLANDER' ethnicity in 2011.","metadata":{},"cell_type":"markdown","id":"a0a6089e-9cb4-4843-ae99-5e644fde70a4"},{"source":"# Replace the rank of the first three ranked names to 'MEDAL'\nnames2.replace({'Rank': {1:'MEDAL', 2:'MEDAL', 3:'MEDAL'}}, inplace=True)\n\n# Replace the rank of the 4th and 5th ranked names to 'ALMOST MEDAL'\nnames2.replace({'Rank': {4:'ALMOST MEDAL', 5:'ALMOST MEDAL'}}, inplace=True)\nprint(names2.head())","metadata":{"executionTime":54,"lastSuccessfullyExecutedCode":"# Replace the rank of the first three ranked names to 'MEDAL'\nnames2.replace({'Rank': {1:'MEDAL', 2:'MEDAL', 3:'MEDAL'}}, inplace=True)\n\n# Replace the rank of the 4th and 5th ranked names to 'ALMOST MEDAL'\nnames2.replace({'Rank': {4:'ALMOST MEDAL', 5:'ALMOST MEDAL'}}, inplace=True)\nprint(names2.head())"},"cell_type":"code","id":"ffdfec2d-48f6-47cf-8cd1-325af157c8a5","execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":"   Year of Birth  Gender  ... Count          Rank\n0           2011  FEMALE  ...   119         MEDAL\n1           2011  FEMALE  ...   106         MEDAL\n2           2011  FEMALE  ...    93         MEDAL\n3           2011  FEMALE  ...    89  ALMOST MEDAL\n4           2011  FEMALE  ...    75  ALMOST MEDAL\n\n[5 rows x 6 columns]\n"}]},{"source":"# ITERATING VIA `.iterrows`","metadata":{},"cell_type":"markdown","id":"47fb8a8f-e095-453e-ac61-7e1460b5c283"},{"source":"### Create a generator for a pandas DataFrame\nAs you've seen in the video, you can easily create a generator out of a pandas DataFrame. Each time you iterate through it, it will yield two elements:\n\nthe index of the respective row\na pandas Series with all the elements of that row\nYou are going to create a generator over the poker dataset, imported as poker_hands. Then, you will print all the elements of the 2nd row, using the generator.\n\nRemember you can always explore the dataset and see how it changes in the IPython Shell, and refer to the slides in the Slides tab.","metadata":{},"cell_type":"markdown","id":"b6848d5a-ab92-4c3f-b5ac-a464f2347c56"},{"source":"# Create a generator over the rows\ngenerator = poker_hands.iterrows()\n\n# Access the elements of the 2nd row\nfirst_element = next(generator)\nsecond_element = next(generator)\nprint(first_element, second_element)","metadata":{"executionTime":48,"lastSuccessfullyExecutedCode":"# Create a generator over the rows\ngenerator = poker_hands.iterrows()\n\n# Access the elements of the 2nd row\nfirst_element = next(generator)\nsecond_element = next(generator)\nprint(first_element, second_element)"},"cell_type":"code","id":"88433173-341d-4921-b462-729d2744cc92","execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":"(0, S1        1\nR1       10\nS2        1\nR2       11\nS3        1\nR3       13\nS4        1\nR4       12\nS5        1\nR5        1\nClass     9\nName: 0, dtype: int64) (1, S1        2\nR1       11\nS2        2\nR2       13\nS3        2\nR3       10\nS4        2\nR4       12\nS5        2\nR5        1\nClass     9\nName: 1, dtype: int64)\n"}]},{"source":"### The iterrows() function for looping\nYou just saw how to create a generator out of a pandas DataFrame. You will now use this generator and see how to take advantage of that method of looping through a pandas DataFrame, still using the poker_hands dataset.\n\nSpecifically, we want the sum of the ranks of all the cards, if the index of the hand is an odd number. The ranks of the cards are located in the odd columns of the DataFrame.","metadata":{},"cell_type":"markdown","id":"f2371afb-f2ed-4315-8bfc-b7a7a46493ea"},{"source":"data_generator = poker_hands.iterrows()\n\nfor index, values in data_generator:\n  \t# Check if index is odd\n    if index%2 != 0:\n      \t# Sum the ranks of all the cards\n        hand_sum = sum([values[1], values[3], values[5], values[7], values[9]])","metadata":{"executionTime":836,"lastSuccessfullyExecutedCode":"data_generator = poker_hands.iterrows()\n\nfor index, values in data_generator:\n  \t# Check if index is odd\n    if index%2 != 0:\n      \t# Sum the ranks of all the cards\n        hand_sum = sum([values[1], values[3], values[5], values[7], values[9]])"},"cell_type":"code","id":"a21ed50d-788b-497e-9b6f-517bc781c18d","execution_count":25,"outputs":[]},{"source":"### `.apply()` function in every cell\nAs you saw in the lesson, you can use .apply() to map a function to every cell of the DataFrame, regardless the column or the row.\n\nYou're going to try it out on the poker_hands dataset. You will use .apply() to square every cell of the DataFrame. The native Python way to square a number n is n**2.","metadata":{},"cell_type":"markdown","id":"bc35c0bb-f651-4791-bdae-1945239afd0f"},{"source":"# Define the lambda transformation\nget_square = lambda x: np.square(x)\n\n# Apply the transformation\ndata_sum = poker_hands.apply(get_square)\nprint(data_sum.head())","metadata":{"executionTime":62,"lastSuccessfullyExecutedCode":"# Define the lambda transformation\nget_square = lambda x: np.square(x)\n\n# Apply the transformation\ndata_sum = poker_hands.apply(get_square)\nprint(data_sum.head())"},"cell_type":"code","id":"f25fa63e-280e-4f1f-8a66-8d6d94bdf807","execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":"   S1   R1  S2   R2  S3   R3  S4   R4  S5   R5  Class\n0   1  100   1  121   1  169   1  144   1    1     81\n1   4  121   4  169   4  100   4  144   4    1     81\n2   9  144   9  121   9  169   9  100   9    1     81\n3  16  100  16  121  16    1  16  169  16  144     81\n4  16    1  16  169  16  144  16  121  16  100     81\n"}]},{"source":"### `.apply()` for rows iteration\n.apply() is a very useful to iterate through the rows of a DataFrame and apply a specific function.\n\nYou will work on a subset of the poker_hands dataset, which includes only the rank of all the five cards of each hand in each row (this subset is generated for you in the script). You're going to get the variance of every hand for all ranks, and every rank for all hands.","metadata":{},"cell_type":"markdown","id":"4e6216fb-dc8d-419d-8746-1c250d9ad643"},{"source":"poker = poker_hand.copy()\nget_variance = lambda x: np.var(x)\n\n# Apply the transformation\ndata_tr = poker[['R1', 'R2', 'R3', 'R4', 'R5']].apply(get_variance, axis=0)\nprint(data_tr.head())","metadata":{"executionTime":50,"lastSuccessfullyExecutedCode":"poker = poker_hand.copy()\nget_variance = lambda x: np.var(x)\n\n# Apply the transformation\ndata_tr = poker[['R1', 'R2', 'R3', 'R4', 'R5']].apply(get_variance, axis=0)\nprint(data_tr.head())"},"cell_type":"code","id":"bd752272-9b17-4561-83d7-4dce67462524","execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":"R1    14.060473\nR2    14.189523\nR3    14.024270\nR4    14.040552\nR5    13.998851\ndtype: float64\n"}]},{"source":"### pandas vectorization in action\nPandas performs more efficiently when an operation is performed to a whole array than to each value separately or sequentially. Vectorization is the process of executing operations on entire arrays.\n\nIn this exercise, you will apply vectorization over pandas series to:\n\ncalculate the mean rank of all the cards in each hand (row)\ncalculate the mean rank of each of the 5 cards in each hand (column)\nYou will use the poker_hands dataset once again to compare both methods' efficiency.","metadata":{},"cell_type":"markdown","id":"55c6f91e-546b-49ea-8922-f2293fa07398"},{"source":"# Calculate the mean rank in each hand\nrow_start_time = time.time()\nmean_r = poker[['R1', 'R2', 'R3', 'R4', 'R5']].mean(axis=1)\nprint(\"Time using pandas vectorization for rows: {} sec\".format(time.time() - row_start_time))\nprint(mean_r.head())\n\n# Calculate the mean rank of each of the 5 card in all hands\ncol_start_time = time.time()\nmean_c = poker[['R1', 'R2', 'R3', 'R4', 'R5']].mean(axis=0)\nprint(\"Time using pandas vectorization for columns: {} sec\".format(time.time() - col_start_time))\nprint(mean_c.head())","metadata":{"executionTime":66,"lastSuccessfullyExecutedCode":"# Calculate the mean rank in each hand\nrow_start_time = time.time()\nmean_r = poker[['R1', 'R2', 'R3', 'R4', 'R5']].mean(axis=1)\nprint(\"Time using pandas vectorization for rows: {} sec\".format(time.time() - row_start_time))\nprint(mean_r.head())\n\n# Calculate the mean rank of each of the 5 card in all hands\ncol_start_time = time.time()\nmean_c = poker[['R1', 'R2', 'R3', 'R4', 'R5']].mean(axis=0)\nprint(\"Time using pandas vectorization for columns: {} sec\".format(time.time() - col_start_time))\nprint(mean_c.head())"},"cell_type":"code","id":"3be0baf4-2463-4d50-abcc-c654c5a31372","execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":"Time using pandas vectorization for rows: 0.0020020008087158203 sec\n0    9.4\n1    9.4\n2    9.4\n3    9.4\n4    9.4\ndtype: float64\nTime using pandas vectorization for columns: 0.0014743804931640625 sec\nR1    6.995242\nR2    7.014194\nR3    7.014154\nR4    6.942463\nR5    6.962735\ndtype: float64\n"}]},{"source":"Similar to pandas working with array, numpy operates with array called ndarrays. Major difference is the `ndarrays` leave out many operations such as indexing, data type checking, etc. As a result, operations on NumPy arrays can be significantly faster than operations on pandas Series. NumPy arrays can be used in place of pandas Series when the additional functionality offered by pandas Series isn’t critical.","metadata":{},"cell_type":"markdown","id":"4170bcf5-428e-4cc8-bfcc-2b90028c9d0f"},{"source":"### Vectorization methods for looping a DataFrame\nNow that you're familiar with vectorization in pandas and NumPy, you're going to compare their respective performances yourself.\n\nYour task is to calculate the variance of all the hands in each hand using the vectorization over pandas Series and then modify your code using the vectorization over Numpy ndarrays method.","metadata":{},"cell_type":"markdown","id":"8000e151-c39a-4171-af6e-d145c11b0b49"},{"source":"# Calculate the variance in each hand\nstart_time = time.time()\npoker_var = poker[['R1', 'R2', 'R3', 'R4', 'R5']].values.var(axis =1, ddof=1)\nprint(\"Time using NumPy vectorization: {} sec\".format(time.time() - start_time))\nprint(poker_var[0:5])","metadata":{"executionTime":82,"lastSuccessfullyExecutedCode":"# Calculate the variance in each hand\nstart_time = time.time()\npoker_var = poker[['R1', 'R2', 'R3', 'R4', 'R5']].values.var(axis =1, ddof=1)\nprint(\"Time using NumPy vectorization: {} sec\".format(time.time() - start_time))\nprint(poker_var[0:5])"},"cell_type":"code","id":"338f9a33-855a-4870-84f6-dad81bf3578b","execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":"Time using NumPy vectorization: 0.003055572509765625 sec\n[23.3 23.3 23.3 23.3 23.3]\n"}]},{"source":"# 4. TRANSFORM AND GROUP BY","metadata":{},"cell_type":"markdown","id":"7a4be184-251a-4eb6-bfa2-967cd65ddca0"},{"source":"### The min-max normalization using .transform()\nA very common operation is the min-max normalization. It consists in rescaling our value of interest by deducting the minimum value and dividing the result by the difference between the maximum and the minimum value. For example, to rescale student's weight data spanning from 160 pounds to 200 pounds, you subtract 160 from each student's weight and divide the result by 40 (200 - 160).\n\nYou're going to define and apply the min-max normalization to all the numerical variables in the restaurant data. You will first group the entries by the time the meal took place (Lunch or Dinner) and then apply the normalization to each group separately.\n\nRemember you can always explore the dataset and see how it changes in the IPython Shell, and refer to the slides in the Slides tab.","metadata":{},"cell_type":"markdown","id":"c028a3f7-535c-4d86-994c-ecea8592e85e"},{"source":"# Define the min-max transformation\nmin_max_tr = lambda x: (x - x.min()) / (x.max() - x.min())\n\n# Group the data according to the time\nrestaurant_grouped = restaurant_data.groupby('time')\n\n# Apply the transformation\nrestaurant_min_max_group = restaurant_grouped.transform(min_max_tr)\nprint(restaurant_min_max_group.head())","metadata":{"executionTime":57,"lastSuccessfullyExecutedCode":"# Define the min-max transformation\nmin_max_tr = lambda x: (x - x.min()) / (x.max() - x.min())\n\n# Group the data according to the time\nrestaurant_grouped = restaurant_data.groupby('time')\n\n# Apply the transformation\nrestaurant_min_max_group = restaurant_grouped.transform(min_max_tr)\nprint(restaurant_min_max_group.head())"},"cell_type":"code","id":"91ce7571-d6b7-4190-b2df-fbfb6482cbde","execution_count":33,"outputs":[{"output_type":"stream","name":"stdout","text":"   total_bill       tip  size\n0    0.291579  0.001111   0.2\n1    0.152283  0.073333   0.4\n2    0.375786  0.277778   0.4\n3    0.431713  0.256667   0.2\n4    0.450775  0.290000   0.6\n"}]},{"source":"### Transforming values to probabilities\nIn this exercise, we will apply a probability distribution function to a pandas DataFrame with group related parameters by transforming the tip variable to probabilities.\n\nThe transformation will be a exponential transformation. The exponential distribution is defined as\n\n**`λ^(-λx).x`**\n\nwhere λ (lambda) is the mean of the group that the observation x belongs to.\n\nYou're going to apply the exponential distribution transformation to the size of each table in the dataset, after grouping the data according to the time of the day the meal took place. Remember to use each group's mean for the value of λ.\n\nIn Python, you can use the exponential as np.exp() from the NumPy library and the mean value as .mean().","metadata":{},"cell_type":"markdown","id":"c9716203-44fe-4f14-a942-c57a59086ab5"},{"source":"# Define the exponential transformation\nexp_tr = lambda x: np.exp((-1*x.mean())*x) * x.mean()\n\n# Group the data according to the time\nrestaurant_grouped = restaurant_data.groupby('time')\n\n# Apply the transformation\nrestaurant_exp_group = restaurant_grouped['tip'].transform(exp_tr)\nprint(restaurant_exp_group.head())","metadata":{"executionTime":65,"lastSuccessfullyExecutedCode":"# Define the exponential transformation\nexp_tr = lambda x: np.exp((-1*x.mean())*x) * x.mean()\n\n# Group the data according to the time\nrestaurant_grouped = restaurant_data.groupby('time')\n\n# Apply the transformation\nrestaurant_exp_group = restaurant_grouped['tip'].transform(exp_tr)\nprint(restaurant_exp_group.head())"},"cell_type":"code","id":"251d9f50-82b3-4daf-b942-2f200d51f9b4","execution_count":34,"outputs":[{"output_type":"stream","name":"stdout","text":"0    0.135141\n1    0.017986\n2    0.000060\n3    0.000108\n4    0.000042\nName: tip, dtype: float64\n"}]},{"source":"### Validation of normalization\nFor this exercise, we will perform a z-score normalization and verify that it was performed correctly.\n\nA distinct characteristic of normalized values is that they have a mean equal to zero and standard deviation equal to one.\n\nAfter you apply the normalization transformation, you can group again on the same variable, and then check the mean and the standard deviation of each group.\n\nYou will apply the normalization transformation to every numeric variable in the poker_grouped dataset, which is the poker_hands dataset grouped by Class.","metadata":{},"cell_type":"markdown","id":"e79b3313-448d-4ad4-b27d-850dba7f440a"},{"source":"zscore = lambda x: (x - x.mean()) / x.std()\n\n# Apply the transformation\npoker_trans = poker.groupby('Class').transform(zscore)\nprint(poker_trans.head())","metadata":{"executionTime":77,"lastSuccessfullyExecutedCode":"zscore = lambda x: (x - x.mean()) / x.std()\n\n# Apply the transformation\npoker_trans = poker.groupby('Class').transform(zscore)\nprint(poker_trans.head())"},"cell_type":"code","id":"e3689ed5-4341-4e29-a485-ef3535a8766d","execution_count":36,"outputs":[{"output_type":"stream","name":"stdout","text":"         S1        R1        S2  ...        R4        S5        R5\n0 -1.380537  0.270364 -1.380537  ...  0.350823 -1.380537 -0.724286\n1 -0.613572  0.495666 -0.613572  ...  0.350823 -0.613572 -0.724286\n2  0.153393  0.720969  0.153393  ... -1.403293  0.153393 -0.724286\n3  0.920358  0.270364  0.920358  ...  1.227881  0.920358  1.267500\n4  0.920358 -1.757363  0.920358  ... -0.526235  0.920358  0.905357\n\n[5 rows x 10 columns]\n"}]},{"source":"# Re-group the grouped object and print each group's means and standard deviation\npoker_regrouped = poker_trans.groupby(poker_hands['Class'])\n\nprint(np.round(poker_regrouped.mean(), 3))\nprint(poker_regrouped.std())","metadata":{"executionTime":79,"lastSuccessfullyExecutedCode":"# Re-group the grouped object and print each group's means and standard deviation\npoker_regrouped = poker_trans.groupby(poker_hands['Class'])\n\nprint(np.round(poker_regrouped.mean(), 3))\nprint(poker_regrouped.std())"},"cell_type":"code","id":"7989df01-efeb-4d36-9ed3-a1ee386f8ca7","execution_count":37,"outputs":[{"output_type":"stream","name":"stdout","text":"        S1   R1   S2   R2   S3   R3   S4   R4   S5   R5\nClass                                                  \n-3    -0.0  0.0  0.0 -0.0 -0.0  0.0  0.0 -0.0  0.0  0.0\n-2     0.0 -0.0  0.0 -0.0  0.0  0.0  0.0 -0.0 -0.0  0.0\n 0    -0.0  0.0 -0.0 -0.0  0.0 -0.0 -0.0 -0.0 -0.0 -0.0\n 3     0.0  0.0  0.0 -0.0 -0.0 -0.0  0.0 -0.0  0.0  0.0\n 4    -0.0 -0.0 -0.0 -0.0  0.0 -0.0 -0.0  0.0  0.0  0.0\n 5    -0.0 -0.0 -0.0  0.0 -0.0  0.0 -0.0  0.0 -0.0  0.0\n 6    -0.0 -0.0 -0.0  0.0  0.0 -0.0  0.0  0.0 -0.0  0.0\n 7     0.0 -0.0 -0.0  0.0 -0.0  0.0  0.0 -0.0 -0.0 -0.0\n 8    -0.0  0.0 -0.0  0.0 -0.0  0.0 -0.0  0.0 -0.0 -0.0\n 9     0.0 -0.0  0.0 -0.0  0.0 -0.0  0.0  0.0  0.0 -0.0\n        S1   R1   S2   R2   S3   R3   S4   R4   S5   R5\nClass                                                  \n-3     1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0\n-2     1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0\n 0     1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0\n 3     1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0\n 4     1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0\n 5     1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0\n 6     1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0\n 7     1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0\n 8     1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0\n 9     1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0\n"}]},{"source":"### Identifying missing values\nThe first step before missing value imputation is to identify if there are missing values in our data, and if so, from which group they arise.\n\nFor the same restaurant_data data you encountered in the lesson, an employee erased by mistake the tips left in 65 tables. The question at stake is how many missing entries came from tables that smokers where present vs tables with no-smokers present.\n\nYour task is to group both datasets according to the smoker variable, count the number or present values and then calculate the difference.\n\nWe're imputing tips to get you to practice the concepts taught in the lesson. From an ethical standpoint, you should not i\n\n#### Group both objects according to smoke condition\n`restaurant_nan_grouped = restaurant_nan.groupby('smoker')`\n\n#### Store the number of present values\n`restaurant_nan_nval = restaurant_nan_grouped['tip'].count()`\n\n#### Print the group-wise missing entries\n`print(restaurant_nan_grouped['total_bill'].count() - restaurant_nan_nval)`","metadata":{},"cell_type":"markdown","id":"629b0a09-4758-440d-b2f8-5934805e04d5"},{"source":"### Missing value imputation\nAs the majority of the real world data contain missing entries, replacing these entries with sensible values can increase the insight you can get from our data.\n\nIn the restaurant dataset, the \"total_bill\" column has some missing entries, meaning that you have not recorded how much some tables have paid. Your task in this exercise is to replace the missing entries with the median value of the amount paid, according to whether the entry was recorded on lunch or dinner (time variable).","metadata":{},"cell_type":"markdown","id":"c5983a1c-1e53-4bc7-9a8b-eae289ef7b45"},{"source":"# Define the lambda function\nmissing_trans = lambda x: x.fillna(x.median())\n\n# Group the data according to time\nrestaurant_grouped = restaurant_data.groupby('time')\n\n# Apply the transformation\nrestaurant_impute = restaurant_grouped.transform(missing_trans)\nprint(restaurant_impute.head())","metadata":{"executionTime":72,"lastSuccessfullyExecutedCode":"# Define the lambda function\nmissing_trans = lambda x: x.fillna(x.median())\n\n# Group the data according to time\nrestaurant_grouped = restaurant_data.groupby('time')\n\n# Apply the transformation\nrestaurant_impute = restaurant_grouped.transform(missing_trans)\nprint(restaurant_impute.head())"},"cell_type":"code","id":"dcf5daf9-5619-4450-97da-a54e53ae4b82","execution_count":40,"outputs":[{"output_type":"stream","name":"stdout","text":"   total_bill   tip  size\n0       16.99  1.01     2\n1       10.34  1.66     3\n2       21.01  3.50     3\n3       23.68  3.31     2\n4       24.59  3.61     4\n"}]},{"source":"### Data filtration\nAs you noticed in the video lesson, you may need to filter your data for various reasons.\n\nIn this exercise, you will use filtering to select a specific part of our DataFrame:\n\nby the number of entries recorded in each day of the week\nby the mean amount of money the customers paid to the restaurant each day of the week","metadata":{},"cell_type":"markdown","id":"ecaa5c4f-e2fd-4f1b-a00a-610f1b157b64"},{"source":"# Filter the days where the count of total_bill is greater than $40\ntotal_bill_40 = restaurant_data.groupby('day').filter(lambda x: x['total_bill'].count() > 40)\n\n# Select only the entries that have a mean total_bill greater than $20\ntotal_bill_20 = total_bill_40.groupby('day').filter(lambda x : x['total_bill'].mean() > 20)\n\n# Print days of the week that have a mean total_bill greater than $20\nprint('Days of the week that have a mean total_bill greater than $20:', total_bill_20.day.unique())","metadata":{"executionTime":74,"lastSuccessfullyExecutedCode":"# Filter the days where the count of total_bill is greater than $40\ntotal_bill_40 = restaurant_data.groupby('day').filter(lambda x: x['total_bill'].count() > 40)\n\n# Select only the entries that have a mean total_bill greater than $20\ntotal_bill_20 = total_bill_40.groupby('day').filter(lambda x : x['total_bill'].mean() > 20)\n\n# Print days of the week that have a mean total_bill greater than $20\nprint('Days of the week that have a mean total_bill greater than $20:', total_bill_20.day.unique())"},"cell_type":"code","id":"606ffa4a-1b49-4c07-bfa3-5e51452a5e62","execution_count":41,"outputs":[{"output_type":"stream","name":"stdout","text":"Days of the week that have a mean total_bill greater than $20: ['Sun' 'Sat']\n"}]}],"metadata":{"colab":{"name":"Welcome to DataCamp Workspaces.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.8.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"editor":"DataCamp Workspace"},"nbformat":4,"nbformat_minor":5}